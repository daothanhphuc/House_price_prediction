{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work Flow\n",
    "\n",
    "## 1. Define the problem:\n",
    "- **Objective**: Predict house prices based on features like location, size, number of different rooms, etc.\n",
    "- **Problem**: Regression (the target variable is continuous)\n",
    "    - Besides, there are 3 other problems includes classification / Clustering / Time-series Forecasting \n",
    "- **Output**: A numerical prediction of the house price.\n",
    "\n",
    "## 2. Data preprocessing:\n",
    "- **Understand data structure** --> evaluate:\n",
    "    - Check the percentage of missing data --> drop? fill?\n",
    "    - Drop data if no important data need to be concerned / more than 50% of the total is missing\n",
    "    - Fill data if < 5-10% missing values \n",
    "        - Fill with the most common value (mode) / creating a new category like \"Missing\"\n",
    "        - Fill using mean/median/interpolation if the data is numerical type\n",
    "    - Check the nunique() data for each features --> group / classify\n",
    "- **Feature Engineering**\n",
    "    - Convert categorical features using one-hot encoding  \n",
    "    - Scale numerical features using standardization.\n",
    "- **Train/Test split** \n",
    "\n",
    "## 3. Choose a Model and Train:\n",
    "- **Process**\n",
    "    - Feed training data into the model.\n",
    "    - Adjust parameters to minimize error. \n",
    "    - Save the trained model for predictions.\n",
    "\n",
    "## 4. Evaluate performance: --> MAE, MSE, ...\n",
    " \n",
    "## 5. Predict and visualize: \n",
    "- Input new data with correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage 259\n",
      "Alley 1369\n",
      "MasVnrType 872\n",
      "MasVnrArea 8\n",
      "BsmtQual 37\n",
      "BsmtCond 37\n",
      "BsmtExposure 38\n",
      "BsmtFinType1 37\n",
      "BsmtFinType2 38\n",
      "Electrical 1\n",
      "FireplaceQu 690\n",
      "GarageType 81\n",
      "GarageYrBlt 81\n",
      "GarageFinish 81\n",
      "GarageQual 81\n",
      "GarageCond 81\n",
      "PoolQC 1453\n",
      "Fence 1179\n",
      "MiscFeature 1406\n"
     ]
    }
   ],
   "source": [
    "#check for missing values\n",
    "for feature in data.columns:\n",
    "    if data[feature].isnull().sum() > 0:\n",
    "        print(feature, data[feature].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop the LotFrontage column\n",
    "data = data.drop('LotFrontage', axis=1)\n",
    "data = data.drop('Id', axis=1) # not useful for prediction\n",
    "data = data.drop('Alley', axis=1) \n",
    "data = data.drop('PoolQC', axis=1) \n",
    "data = data.drop('Fence', axis=1) \n",
    "data = data.drop('MiscFeature', axis=1) \n",
    "data = data.drop('FireplaceQu', axis=1) \n",
    "data = data.drop('MasVnrType', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasVnrArea 8\n",
      "BsmtQual 37\n",
      "BsmtCond 37\n",
      "BsmtExposure 38\n",
      "BsmtFinType1 37\n",
      "BsmtFinType2 38\n",
      "Electrical 1\n",
      "GarageType 81\n",
      "GarageYrBlt 81\n",
      "GarageFinish 81\n",
      "GarageQual 81\n",
      "GarageCond 81\n"
     ]
    }
   ],
   "source": [
    "#check for missing values\n",
    "for feature in data.columns:\n",
    "    if data[feature].isnull().sum() > 0:\n",
    "        print(feature, data[feature].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Street ['Pave' 'Grvl']\n",
      "Utilities ['AllPub' 'NoSeWa']\n",
      "CentralAir ['Y' 'N']\n"
     ]
    }
   ],
   "source": [
    "#check for feature have binary values\n",
    "for feature in data.columns:\n",
    "    if len(data[feature].unique()) == 2:\n",
    "        print(feature, data[feature].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning ['RL' 'RM' 'C (all)' 'FV' 'RH']\n",
      "LotShape ['Reg' 'IR1' 'IR2' 'IR3']\n",
      "LandContour ['Lvl' 'Bnk' 'Low' 'HLS']\n",
      "LotConfig ['Inside' 'FR2' 'Corner' 'CulDSac' 'FR3']\n",
      "LandSlope ['Gtl' 'Mod' 'Sev']\n",
      "Neighborhood ['CollgCr' 'Veenker' 'Crawfor' 'NoRidge' 'Mitchel' 'Somerst' 'NWAmes'\n",
      " 'OldTown' 'BrkSide' 'Sawyer' 'NridgHt' 'NAmes' 'SawyerW' 'IDOTRR'\n",
      " 'MeadowV' 'Edwards' 'Timber' 'Gilbert' 'StoneBr' 'ClearCr' 'NPkVill'\n",
      " 'Blmngtn' 'BrDale' 'SWISU' 'Blueste']\n",
      "Condition1 ['Norm' 'Feedr' 'PosN' 'Artery' 'RRAe' 'RRNn' 'RRAn' 'PosA' 'RRNe']\n",
      "Condition2 ['Norm' 'Artery' 'RRNn' 'Feedr' 'PosN' 'PosA' 'RRAn' 'RRAe']\n",
      "BldgType ['1Fam' '2fmCon' 'Duplex' 'TwnhsE' 'Twnhs']\n",
      "HouseStyle ['2Story' '1Story' '1.5Fin' '1.5Unf' 'SFoyer' 'SLvl' '2.5Unf' '2.5Fin']\n",
      "RoofStyle ['Gable' 'Hip' 'Gambrel' 'Mansard' 'Flat' 'Shed']\n",
      "RoofMatl ['CompShg' 'WdShngl' 'Metal' 'WdShake' 'Membran' 'Tar&Grv' 'Roll'\n",
      " 'ClyTile']\n",
      "Exterior1st ['VinylSd' 'MetalSd' 'Wd Sdng' 'HdBoard' 'BrkFace' 'WdShing' 'CemntBd'\n",
      " 'Plywood' 'AsbShng' 'Stucco' 'BrkComm' 'AsphShn' 'Stone' 'ImStucc'\n",
      " 'CBlock']\n",
      "Exterior2nd ['VinylSd' 'MetalSd' 'Wd Shng' 'HdBoard' 'Plywood' 'Wd Sdng' 'CmentBd'\n",
      " 'BrkFace' 'Stucco' 'AsbShng' 'Brk Cmn' 'ImStucc' 'AsphShn' 'Stone'\n",
      " 'Other' 'CBlock']\n",
      "ExterQual ['Gd' 'TA' 'Ex' 'Fa']\n",
      "ExterCond ['TA' 'Gd' 'Fa' 'Po' 'Ex']\n",
      "Foundation ['PConc' 'CBlock' 'BrkTil' 'Wood' 'Slab' 'Stone']\n",
      "BsmtQual ['Gd' 'TA' 'Ex' nan 'Fa']\n",
      "BsmtCond ['TA' 'Gd' nan 'Fa' 'Po']\n",
      "BsmtExposure ['No' 'Gd' 'Mn' 'Av' nan]\n",
      "BsmtFinType1 ['GLQ' 'ALQ' 'Unf' 'Rec' 'BLQ' nan 'LwQ']\n",
      "BsmtFinType2 ['Unf' 'BLQ' nan 'ALQ' 'Rec' 'LwQ' 'GLQ']\n",
      "Heating ['GasA' 'GasW' 'Grav' 'Wall' 'OthW' 'Floor']\n",
      "HeatingQC ['Ex' 'Gd' 'TA' 'Fa' 'Po']\n",
      "Electrical ['SBrkr' 'FuseF' 'FuseA' 'FuseP' 'Mix' nan]\n",
      "KitchenQual ['Gd' 'TA' 'Ex' 'Fa']\n",
      "Functional ['Typ' 'Min1' 'Maj1' 'Min2' 'Mod' 'Maj2' 'Sev']\n",
      "GarageType ['Attchd' 'Detchd' 'BuiltIn' 'CarPort' nan 'Basment' '2Types']\n",
      "GarageFinish ['RFn' 'Unf' 'Fin' nan]\n",
      "GarageQual ['TA' 'Fa' 'Gd' nan 'Ex' 'Po']\n",
      "GarageCond ['TA' 'Fa' nan 'Gd' 'Po' 'Ex']\n",
      "PavedDrive ['Y' 'N' 'P']\n",
      "SaleType ['WD' 'New' 'COD' 'ConLD' 'ConLI' 'CWD' 'ConLw' 'Con' 'Oth']\n",
      "SaleCondition ['Normal' 'Abnorml' 'Partial' 'AdjLand' 'Alloca' 'Family']\n"
     ]
    }
   ],
   "source": [
    "# check for feature have more than 5 values and is a string type\n",
    "for feature in data.columns:\n",
    "    if len(data[feature].unique()) > 2 and data[feature].dtype == 'object':\n",
    "        print(feature, data[feature].unique())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Street [0 1]\n",
      "Utilities [0 1]\n",
      "CentralAir [1 0]\n"
     ]
    }
   ],
   "source": [
    "binary_features = ['Street', 'Utilities', 'CentralAir']\n",
    "\n",
    "#convert binary features to 0 and 1\n",
    "binary_mappings = {\n",
    "    'Street': {'Pave': 0, 'Grvl': 1},\n",
    "    'Utilities': {'AllPub': 0, 'NoSeWa': 1},\n",
    "    'CentralAir': {'N': 0, 'Y': 1}\n",
    "}\n",
    "\n",
    "for feature in binary_features:\n",
    "    data[feature] = data[feature].map(binary_mappings[feature])\n",
    "\n",
    "for feature in binary_features:\n",
    "    print(feature, data[feature].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(string_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in data.columns:\n",
    "    if len(data[feature].unique()) > 2 and data[feature].dtype == 'object':\n",
    "        data = pd.get_dummies(data, columns=[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MSZoning_FV', 'MSZoning_RH', 'MSZoning_RL', 'MSZoning_RM',\n",
      "       'LotShape_IR1', 'LotShape_IR2', 'LotShape_IR3', 'LotShape_Reg',\n",
      "       'LandContour_Bnk', 'LandContour_HLS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print the name of the columns using get_dummies\n",
    "print(data.columns[40:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN with 0 before converting to integers\n",
    "data = data.fillna(0).astype(int)\n",
    "data= data.astype(int)\n",
    "# avoid multicollinearity ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical features to visualize\n",
    "numerical_features = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n",
    "\n",
    "# Create histograms for each numerical feature\n",
    "plt.figure(figsize=(10, 6))\n",
    "for feature in numerical_features:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(data[feature], bins=20, edgecolor='black', alpha=0.7)\n",
    "    plt.title(f\"Distribution of {feature}\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the model --> Standardization if choosing ones sensitive to feature scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply to 'area' only\n",
    "data['area'] = scaler.fit_transform(data[['area']])\n",
    "\n",
    "# Check scaled values\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding \"price\" column\n",
    "X= data.drop(columns=['price'])\n",
    "\n",
    "y= data['price'] \n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# print the number of samples in each set\n",
    "print(X_train.shape[0])\n",
    "print(X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Visualize the process of training\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(range(len(y_train)), y_train, label='Actual')\n",
    "plt.plot(range(len(y_train)), model.predict(X_train), label='Predicted')\n",
    "plt.legend()\n",
    "plt.title('Training set: Actual vs Predicted')\n",
    "plt.xlabel('Sample number')\n",
    "plt.ylabel('Price') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print('Mean Absolute Error:', mae)\n",
    "print('Mean Squared Error:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some large errors --> ouliers or missing features \n",
    "## --> Must be ouliers since all missing ones are being handle before "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(data['price'])\n",
    "plt.title(\"Box Plot of House Prices\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 8))\n",
    "\n",
    "# for i, feature in enumerate(numerical_features, 1):\n",
    "#     plt.subplot(2, 3, i)  # Arrange subplots in a grid (2 rows, 3 columns)\n",
    "    \n",
    "#     # Calculate IQR\n",
    "#     Q1 = data[feature].quantile(0.25)\n",
    "#     Q3 = data[feature].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower_bound = Q1 - 2.0 * IQR\n",
    "#     upper_bound = Q3 + 2.0 * IQR\n",
    "    \n",
    "#     # Plot boxplot\n",
    "#     sns.boxplot(x=data[feature], color=\"skyblue\")\n",
    "    \n",
    "#     # Add vertical lines for IQR range\n",
    "#     plt.axvline(Q1, color='blue', linestyle='dashed', label=\"Q1\")\n",
    "#     plt.axvline(Q3, color='green', linestyle='dashed', label=\"Q3\")\n",
    "#     plt.axvline(lower_bound, color='red', linestyle='dashed', label=\"Lower Bound\")\n",
    "#     plt.axvline(upper_bound, color='red', linestyle='dashed', label=\"Upper Bound\")\n",
    "    \n",
    "#     plt.title(f\"Box Plot of {feature}\")\n",
    "#     plt.xlabel(feature)\n",
    "#     plt.legend()\n",
    "\n",
    "# plt.tight_layout()  \n",
    "# plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, feature in enumerate(numerical_features, 1):\n",
    "    plt.subplot(2, 3, i)  # Arrange subplots in a grid (2 rows, 3 columns)\n",
    "    sns.boxplot(x=data[feature], color=\"lightcoral\")  # Use different color for before cleaning\n",
    "    plt.title(f\"Box Plot of {feature} (Before Cleaning)\")\n",
    "    plt.xlabel(feature)\n",
    "\n",
    "plt.tight_layout()  # Adjust layout for better visualization\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_outliers_iqr(data, features):\n",
    "#     for feature in features:\n",
    "#         Q1 = data[feature].quantile(0.25) \n",
    "#         Q3 = data[feature].quantile(0.75) \n",
    "#         IQR = Q3 - Q1  \n",
    "#         lower_bound = Q1 - 2.0 * IQR # choose threshold = 3.0 instead of 1.5 to remove more outliers\n",
    "#         upper_bound = Q3 + 2.0 * IQR\n",
    "        \n",
    "#         # Remove rows where feature value is outside the IQR bounds\n",
    "#         data = data[(data[feature] >= lower_bound) & (data[feature] <= upper_bound)]\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_zscore(df, features, threshold=3):\n",
    "    df_cleaned = df.copy()\n",
    "    for feature in features:\n",
    "        df_cleaned = df_cleaned[np.abs(zscore(df_cleaned[feature])) < threshold]  \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = remove_outliers_zscore(data, numerical_features)\n",
    "# Print shape of data before and after removing outliers\n",
    "print(f\"Original dataset shape: {data.shape}\")\n",
    "print(f\"Cleaned dataset shape: {data_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 8))\n",
    "\n",
    "# for i, feature in enumerate(numerical_features, 1):\n",
    "#     plt.subplot(2, 3, i)  # Arrange subplots in a grid (2 rows, 3 columns)\n",
    "#     sns.boxplot(x=data_cleaned[feature], color=\"skyblue\")\n",
    "#     plt.title(f\"Box Plot of {feature} after removing outliers\")\n",
    "#     plt.xlabel(feature)\n",
    "\n",
    "# plt.tight_layout()  # Adjust layout for better visualization\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, feature in enumerate(numerical_features, 1):\n",
    "    plt.subplot(2, 3, i)  # Arrange subplots in a grid (2 rows, 3 columns)\n",
    "    sns.boxplot(x=data_cleaned[feature], color=\"skyblue\")\n",
    "    plt.title(f\"Box Plot of {feature} (After Z-score Outlier Removal)\")\n",
    "    plt.xlabel(feature)\n",
    "\n",
    "plt.tight_layout()  # Adjust layout for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['bathrooms'].value_counts())  # Check distribution before removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_cleaned['bathrooms'].value_counts())  # Check distribution before removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding \"price\" column\n",
    "X= data_cleaned.drop(columns=['price'])\n",
    "\n",
    "y= data_cleaned['price'] \n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# print the number of samples in each set\n",
    "print(X_train.shape[0])\n",
    "print(X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model.predict(X_test)\n",
    "#mae \n",
    "mae = mean_absolute_error(y_test, y_pred2)\n",
    "#mse\n",
    "mse = mean_squared_error(y_test, y_pred2)\n",
    "print('Mean Absolute Error:', mae)\n",
    "print('Mean Squared Error:', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shared_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
